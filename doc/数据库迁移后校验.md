你希望校验数据库迁移后源库和目标库是否「相等」（即数据一致性、结构一致性），这是数据迁移后的核心校验环节，需要从「**结构校验**」和「**数据校验**」两个维度展开，同时兼顾不同场景的效率和准确性，下面提供一套完整、可落地的校验方案：

### 一、先明确：「数据库相等」的核心校验维度
数据库迁移后的「相等」并非单纯的「数据完全一致」，而是包含两个核心层面，缺一不可：
1.  **结构相等**：源库和目标库的表、字段、索引、约束、视图、存储过程等元数据完全一致；
2.  **数据相等**：源库和目标库的每条记录、每个字段的值完全一致（允许少量场景下的格式兼容差异，如日期格式）。

### 二、第一部分：结构校验（元数据一致性）
结构校验是数据校验的前提，若结构不一致，数据校验无意义，推荐「自动工具校验」+「手动抽查」结合。

#### 1.  自动工具校验（高效、全面，推荐生产环境使用）
##### （1）适用工具
- **开源工具**：`mysqldiff`（MySQL 官方推荐，专门用于对比表结构）、`SchemaSpy`（生成数据库结构文档，便于对比）、`Flyway`/`Liquibase`（版本化管理schema，迁移前后可对比）；
- **商用工具**：Navicat（「结构同步」功能可对比差异）、DataGrip（内置数据库结构对比工具）、阿里云 DTS 数据迁移工具（自带结构校验功能）。

##### （2）核心操作（以 `mysqldiff` 为例，MySQL 专属）
`mysqldiff` 可以直接对比两个数据库的表结构，输出差异明细（字段类型、长度、约束、索引等）。
1.  安装 `mysqldiff`（属于 `mysql-utilities` 工具集）：
    ```bash
    # CentOS 安装
    yum install mysql-utilities
    # Ubuntu 安装
    apt-get install mysql-utilities
    ```
2.  执行结构对比命令：
    ```bash
    mysqldiff --server1=user1:password1@host1:3306 --server2=user2:password2@host2:3306 \
    --databases db_source db_target \
    --skip-table-options \
    --verbose
    ```
    - 核心参数说明：
        - `--server1/--server2`：源库和目标库的连接信息；
        - `--databases`：指定要对比的两个数据库；
        - `--skip-table-options`：忽略表的存储引擎、字符集等环境相关差异（若迁移后环境不同，可开启）；
        - `--verbose`：输出详细差异信息。
3.  解读结果：
    - 输出 `OK` 表示结构一致；
    - 输出 `DIFF` 表示存在差异，会详细列出「哪个表、哪个字段、差异是什么」（如字段类型从 `INT(11)` 变为 `BIGINT(20)`、缺少主键约束等）。

##### （3）Navicat 图形化对比（适合非专业运维人员）
1.  同时连接源库和目标库；
2.  右键点击源库 → 「结构同步」→ 选择目标库；
3.  工具会自动扫描并列出所有结构差异，支持「一键同步差异」和「生成差异报告」。

#### 2.  手动抽查（补充验证，针对核心表）
对于核心业务表（如订单表、用户表），手动抽查以下关键结构，避免工具遗漏：
1.  表的核心字段：字段名称、数据类型、长度、是否允许为 `NULL`、默认值；
2.  约束：主键、外键、唯一索引、非空约束；
3.  索引：查询常用索引是否存在（避免迁移后索引丢失导致性能问题）；
4.  特殊对象：视图、存储过程、触发器、函数（工具对这类对象的对比支持较弱，需手动验证）。

### 三、第二部分：数据校验（数据内容一致性）
数据校验是核心，需根据「数据量大小」选择不同的校验方案，优先保证「准确性」，再兼顾「效率」。

#### 场景 1：小数据量（单表数据 < 10 万条，总数据量 < 100 万条）—— 全量对比（最准确）
适合小型数据库，直接对比每条记录、每个字段的值，无遗漏。

##### 方案 1：SQL 直接对比（无工具依赖，简单高效）
核心思路：通过「联表查询」对比源库和目标库的记录，找出缺失、多余、字段值不一致的记录。
1.  前提：在目标库中创建源库的「链接表」（或直接在同一台数据库服务器上对比，减少跨网络开销）；
    - 示例（创建 MySQL 链接表，通过 `FEDERATED` 引擎）：
      ```sql
      -- 在目标库中创建源库 t_user 表的链接表
      CREATE TABLE t_user_source (
        id INT PRIMARY KEY AUTO_INCREMENT,
        phone VARCHAR(11) UNIQUE NOT NULL,
        name VARCHAR(20) NOT NULL,
        age INT DEFAULT 18
      ) ENGINE=FEDERATED CONNECTION='mysql://user1:password1@host1:3306/db_source/t_user';
      ```
2.  全量对比核心 SQL（以 `t_user` 表为例）：
    - （1）查询「源库有、目标库无」的记录（缺失记录）：
      ```sql
      SELECT * FROM t_user_source 
      WHERE id NOT IN (SELECT id FROM t_user_target);
      ```
    - （2）查询「目标库有、源库无」的记录（多余记录）：
      ```sql
      SELECT * FROM t_user_target 
      WHERE id NOT IN (SELECT id FROM t_user_source);
      ```
    - （3）查询「主键存在但字段值不一致」的记录（字段差异）：
      ```sql
      SELECT 
        s.id,
        s.phone AS source_phone, t.phone AS target_phone,
        s.name AS source_name, t.name AS target_name,
        s.age AS source_age, t.age AS target_age
      FROM t_user_source s
      JOIN t_user_target t ON s.id = t.id
      WHERE 
        s.phone <> t.phone 
        OR s.name <> t.name 
        OR s.age <> t.age;
      ```
3.  注意事项：
    - 对比时忽略「自增主键以外的自动生成字段」（如 `create_time` 若为迁移时自动生成，可能存在差异）；
    - 对于 `NULL` 值，需用 `IS NULL` 单独判断（`<> ` 无法识别 `NULL` 差异）。

##### 方案 2：导出文件对比（适合跨数据库类型迁移，如 MySQL → PostgreSQL）
1.  分别从源库和目标库导出全量数据为 CSV 文件（统一格式：编码 UTF-8、字段分隔符 `,`、换行符 `\n`）：
    - MySQL 导出命令（`mysqldump`）：
      ```bash
      mysqldump -uuser1 -ppassword1 -hhost1 -P3306 \
      --tab=/tmp/ --fields-terminated-by=, --fields-enclosed-by=\" \
      db_source t_user
      ```
    - 该命令会生成 `t_user.sql`（表结构）和 `t_user.txt`（数据，CSV 格式）。
2.  使用文件对比工具对比两个 CSV 文件：
    - 命令行工具：`diff`（Linux 内置）、`md5sum`（先校验文件 MD5，若一致则数据无差异，若不一致再用 `diff` 找明细）；
      ```bash
      # 校验 MD5（快速判断是否一致）
      md5sum /tmp/db_source/t_user.txt
      md5sum /tmp/db_target/t_user.txt
      # 对比差异明细
      diff /tmp/db_source/t_user.txt /tmp/db_target/t_user.txt
      ```
    - 图形化工具：Beyond Compare、WinMerge（适合Windows环境，直观展示差异行）。

#### 场景 2：大数据量（单表数据 > 10 万条，总数据量 > 100 万条）—— 抽样对比 + 校验和对比（效率优先）
全量对比耗时过长（甚至可能导致数据库压力过大），采用「「校验和对比（宏观一致）」+「抽样对比（微观准确）」」的方案。

##### 方案 1：校验和对比（宏观判断数据是否一致）
核心思路：对每个表的所有记录计算「全局校验和」，若源库和目标库的校验和一致，则认为数据宏观一致（无大量缺失或篡改）。
1.  常用校验和计算方式（MySQL 为例）：
    - （1）基于单字段的 `MD5` 累加（适合核心字段，如主键+核心业务字段）：
      ```sql
      -- 源库计算 t_user 表的校验和
      SELECT MD5(GROUP_CONCAT(CONCAT(id, phone, name, age) ORDER BY id)) AS table_checksum
      FROM t_user_source;
      
      -- 目标库计算 t_user 表的校验和
      SELECT MD5(GROUP_CONCAT(CONCAT(id, phone, name, age) ORDER BY id)) AS table_checksum
      FROM t_user_target;
      ```
    - （2）基于全表的 `CHECKSUM TABLE`（MySQL 内置，快速但精度略低）：
      ```sql
      -- 源库计算校验和
      CHECKSUM TABLE t_user_source;
      -- 目标库计算校验和
      CHECKSUM TABLE t_user_target;
      ```
2.  注意事项：
    - `GROUP_CONCAT` 有长度限制（默认 1024 字符），需先调整参数：`SET GLOBAL group_concat_max_len = 1024000;`；
    - 校验和对「字段顺序、大小写、空格」敏感，需保证源库和目标库的导出格式一致；
    - 该方案只能判断「宏观一致」，无法找出具体差异记录，需配合抽样对比。

##### 方案 2：分层抽样对比（微观验证数据准确性）
核心思路：按照「主键范围」或「业务维度」分层抽样，对比样本数据的一致性，若样本无差异，则认为整体数据无差异（统计意义上的一致）。
1.  抽样策略（以主键为自增 INT 为例）：
    - 均匀抽样：按主键范围分成 100 层，每层随机抽取 100 条记录，共 1 万条样本；
    - 核心数据抽样：优先抽取「核心业务记录」（如订单状态为「已支付」、用户等级为「VIP」的记录）；
    - 边界值抽样：抽取主键最小值、最大值、临界值（如 10 万、100 万）对应的记录。
2.  抽样对比操作：
    - 编写 SQL 抽取样本数据：
      ```sql
      -- 源库抽取 1000 条样本（主键均匀分布）
      SELECT * FROM t_user_source
      WHERE id BETWEEN 1 AND 1000000
      ORDER BY RAND()
      LIMIT 1000;
      ```
    - 将源库和目标库的样本数据导出为 CSV 文件，用 Beyond Compare 对比；
    - 若样本无差异，则认为整体数据一致；若样本存在差异，扩大抽样范围，定位差异原因。

#### 场景 3：超大数据量（千万级以上）—— 专业工具校验（生产环境首选）
对于千万级、亿级数据，手动方案效率过低，推荐使用专业的数据校验工具，支持「分布式校验」「增量校验」，兼顾效率和准确性。

##### 推荐工具
1.  **阿里云 DTS 数据校验**：迁移后自动进行「全量数据校验」和「增量数据校验」，输出详细校验报告，支持定位具体差异记录；
2.  **DataX**：开源数据同步工具，内置「数据校验」功能，支持多种数据库类型，可配置校验规则；
3.  **Great Expectations**：开源数据质量校验工具，支持定义「数据期望」（如字段非空、数值范围、唯一约束），自动对比源库和目标库是否满足期望。

##### 工具核心优势
- 分布式处理：支持多线程、多节点并行校验，大幅提升效率；
- 智能差异定位：直接输出差异记录的主键、字段值，无需手动编写 SQL；
- 低侵入性：对源库和目标库的压力小，不会影响线上业务。

### 四、第三部分：特殊场景的补充校验
1.  **有自增主键/自动生成字段的表**：忽略「迁移过程中自动生成的字段」（如 `create_time`、`update_time`），仅对比核心业务字段；
2.  **有 BLOB/TEXT 大字段的表**：不适合计算 MD5 校验和（耗时过长），可采用「抽样对比」+「长度校验」（对比大字段的长度是否一致）；
3.  **增量迁移后的校验**：先校验「全量数据基线」，再校验「增量数据（迁移期间的变更）」，确保无遗漏；
4.  **跨数据库类型迁移（如 MySQL → Oracle）**：重点校验「数据类型兼容差异」（如 `INT` → `NUMBER`、`VARCHAR` → `VARCHAR2`），避免字段值截断或格式错误。

### 五、校验结果处理与闭环
1.  **若结构/数据一致**：记录校验报告（工具输出、抽样结果、校验时间），完成迁移闭环；
2.  **若存在差异**：
    - 先定位差异原因（是迁移工具问题、结构不一致、网络传输丢失还是数据格式兼容问题）；
    - 针对差异进行修复（如同步结构差异、重新迁移差异记录）；
    - 修复后重新执行校验，直到结构和数据完全一致。

### 总结
1.  校验核心：「结构校验」是前提，「数据校验」是核心，需分维度、分场景选择合适的方案；
2.  方案选择：小数据量用「全量对比」，大数据量用「校验和+抽样对比」，超大数据量用「专业工具」；
3.  关键原则：优先保证「准确性」，再兼顾「效率」，核心业务表必须做到「全量无差异」。

通过这套方案，可全面验证数据库迁移后的一致性，避免因迁移遗漏或错误导致线上业务问题。