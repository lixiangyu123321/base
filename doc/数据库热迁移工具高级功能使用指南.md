# 数据库热迁移工具高级功能使用指南

## 文档信息

- **创建日期**: 2025-01-27
- **功能模块**: `com.lixiangyu.common.migration`
- **版本**: 2.0

---

## 一、功能概述

### 1.1 新增功能

基于基础迁移功能，新增了以下高级功能：

1. **Binlog 增量同步**：实时监听 MySQL binlog，实现增量数据同步
2. **双写功能**：通过 `@DualWrite` 注解实现业务双写（源库+目标库）
3. **数据校验增强**：支持不一致数据的自动修复
4. **断点续传**：支持迁移任务中断后继续
5. **进度查询**：实时查询迁移任务进度
6. **任务调度**：支持定时任务和任务队列

### 1.2 功能对比

| 功能 | 基础版本 | 高级版本 |
|------|---------|---------|
| 全量迁移 | ✅ | ✅ |
| 增量同步 | ❌ | ✅（Binlog） |
| 双写功能 | ❌ | ✅（注解） |
| 数据校验 | ✅（基础） | ✅（增强+自动修复） |
| 断点续传 | ❌ | ✅ |
| 进度查询 | ❌ | ✅ |
| 任务调度 | ❌ | ✅ |

---

## 二、Binlog 增量同步

### 2.1 功能说明

通过监听 MySQL binlog 日志，实时捕获数据库变更（INSERT/UPDATE/DELETE），并同步到目标数据库。

### 2.2 使用方式

#### 方式一：编程式使用

```java
@Autowired
private BinlogListener binlogListener;

public void startBinlogSync() {
    BinlogListener.BinlogListenerConfig config = BinlogListener.BinlogListenerConfig.builder()
            .sourceDataSource(sourceDataSource)
            .targetDataSource(targetDataSource)
            .tables(Arrays.asList("user", "order"))  // 要监听的表
            .binlogFile("mysql-bin.000001")          // 断点续传：binlog 文件名
            .binlogPosition(12345L)                  // 断点续传：binlog 位置
            .serverId(1L)                            // MySQL 复制服务器ID
            .build();
    
    String taskId = binlogListener.startListening(config);
    log.info("Binlog 监听已启动，Task ID: {}", taskId);
}
```

#### 方式二：RESTful API

```bash
# 启动 Binlog 监听
curl -X POST http://localhost:8080/api/migration/binlog/start \
  -H "Content-Type: application/json" \
  -d '{
    "sourceDataSource": "sourceDataSource",
    "targetDataSource": "targetDataSource",
    "tables": ["user", "order"],
    "binlogFile": "mysql-bin.000001",
    "binlogPosition": 12345,
    "serverId": 1
  }'

# 查询监听状态
curl http://localhost:8080/api/migration/binlog/status/{taskId}

# 停止监听
curl -X POST http://localhost:8080/api/migration/binlog/stop/{taskId}
```

### 2.3 配置要求

**MySQL 配置**（需要开启 binlog）：

```ini
# my.cnf
[mysqld]
log-bin=mysql-bin
binlog-format=ROW
server-id=1
```

**权限要求**：

```sql
-- 需要 REPLICATION SLAVE 权限
GRANT REPLICATION SLAVE ON *.* TO 'username'@'%';
FLUSH PRIVILEGES;
```

### 2.4 断点续传

支持从指定的 binlog 位置继续同步：

```java
BinlogListener.BinlogListenerConfig config = BinlogListener.BinlogListenerConfig.builder()
        .binlogFile("mysql-bin.000001")  // 从指定文件开始
        .binlogPosition(12345L)            // 从指定位置开始
        .build();
```

---

## 三、双写功能

### 3.1 功能说明

通过 `@DualWrite` 注解，自动将数据库写入操作同时写入源库和目标库，适用于数据库迁移期间的平滑切换。

### 3.2 使用方式

#### 基础使用

```java
@Service
public class UserService {
    
    @DualWrite(
        source = "sourceDataSource",
        target = "targetDataSource",
        tables = {"user"},
        rollbackOnFailure = true
    )
    public void saveUser(User user) {
        // 业务逻辑：保存用户
        // 注解会自动将操作同时写入源库和目标库
    }
}
```

#### 高级配置

```java
@DualWrite(
    source = "sourceDataSource",
    target = "targetDataSource",
    tables = {"user", "order"},
    order = DualWrite.WriteOrder.SOURCE_FIRST,  // 先写源库
    async = false,                                // 同步写入
    rollbackOnFailure = true,                     // 失败回滚
    retryTimes = 3,                               // 重试3次
    retryInterval = 1000                          // 重试间隔1秒
)
public void saveOrder(Order order) {
    // 业务逻辑
}
```

### 3.3 写入顺序

| 顺序 | 说明 | 适用场景 |
|------|------|---------|
| `SOURCE_FIRST` | 先写源库，再写目标库 | 默认，保证源库优先 |
| `TARGET_FIRST` | 先写目标库，再写源库 | 目标库为主库时 |
| `PARALLEL` | 并行写入 | 性能要求高时 |

### 3.4 异步写入

```java
@DualWrite(
    async = true  // 异步写入，不阻塞主流程
)
public void saveUser(User user) {
    // 主流程立即返回，目标库写入在后台执行
}
```

### 3.5 失败处理

```java
@DualWrite(
    rollbackOnFailure = true  // 目标库写入失败时，回滚源库操作
)
public void saveUser(User user) {
    // 如果目标库写入失败，会抛出异常，触发源库回滚
}
```

---

## 四、数据校验增强

### 4.1 功能说明

在基础校验（记录数校验）的基础上，增加了：
1. **数据内容校验**：逐条比较数据内容
2. **自动修复**：自动修复不一致的数据

### 4.2 使用方式

```java
MigrationConfig config = MigrationConfig.builder()
        .source(...)
        .target(...)
        .enableValidation(true)           // 启用校验
        .autoFixInconsistent(true)       // 自动修复不一致数据
        .build();

MigrationResult result = migrationService.migrate(config);

// 查看校验结果
MigrationResult.ValidationResult validation = result.getValidationResult();
if (!validation.isPassed()) {
    // 查看不一致的表
    for (MigrationResult.TableValidationDetail detail : validation.getTableDetails()) {
        if (!detail.isConsistent()) {
            log.warn("表 {} 数据不一致，源: {}, 目标: {}", 
                    detail.getTableName(),
                    detail.getSourceRecordCount(),
                    detail.getTargetRecordCount());
            
            // 查看不一致的记录
            if (detail.getInconsistentRecords() != null) {
                for (MigrationResult.InconsistentRecord record : detail.getInconsistentRecords()) {
                    log.warn("不一致记录，主键: {}", record.getPrimaryKey());
                }
            }
        }
    }
}
```

### 4.3 自动修复

启用自动修复后，系统会自动：
1. 检测不一致的记录
2. 从源库获取完整数据
3. 使用 `REPLACE INTO` 或 `UPDATE` 修复目标库数据

---

## 五、断点续传

### 5.1 功能说明

支持迁移任务中断后，从断点位置继续执行，避免重复迁移。

### 5.2 使用方式

```java
MigrationConfig config = MigrationConfig.builder()
        .source(...)
        .target(...)
        .enableCheckpoint(true)          // 启用断点续传
        .checkpointInterval(10000)       // 每10000条记录保存一次断点
        .build();

MigrationResult result = migrationService.migrate(config);
```

### 5.3 查询断点

```java
@Autowired
private MigrationTaskManager taskManager;

// 查询断点信息
MigrationTaskManager.MigrationCheckpoint checkpoint = 
        taskManager.getCheckpoint(taskId, "user");
if (checkpoint != null) {
    log.info("断点信息: 表={}, 位置={}, 已迁移={}", 
            checkpoint.getTableName(),
            checkpoint.getPosition(),
            checkpoint.getMigratedRecords());
}
```

### 5.4 RESTful API

```bash
# 查询断点信息
curl http://localhost:8080/api/migration/progress/checkpoint/{taskId}?tableName=user
```

---

## 六、进度查询

### 6.1 功能说明

实时查询迁移任务的进度，包括：
- 总表数/已完成表数
- 总记录数/已完成记录数
- 进度百分比
- 预计剩余时间

### 6.2 使用方式

#### 编程式查询

```java
@Autowired
private MigrationTaskManager taskManager;

// 查询进度
MigrationTaskManager.MigrationProgress progress = taskManager.getProgress(taskId);
if (progress != null) {
    log.info("迁移进度: 表 {}/{}, 记录 {}/{}, 表进度 {}%, 记录进度 {}%",
            progress.getCompletedTables(),
            progress.getTotalTables(),
            progress.getCompletedRecords(),
            progress.getTotalRecords(),
            progress.getTableProgress(),
            progress.getRecordProgress());
}
```

#### RESTful API

```bash
# 查询进度
curl http://localhost:8080/api/migration/progress/{taskId}

# 查询任务信息
curl http://localhost:8080/api/migration/progress/task/{taskId}
```

### 6.3 进度信息

```json
{
  "taskId": "xxx",
  "totalTables": 10,
  "completedTables": 5,
  "totalRecords": 1000000,
  "completedRecords": 500000,
  "tableProgress": 50.0,
  "recordProgress": 50.0,
  "startTime": "2025-01-27T10:00:00",
  "updateTime": "2025-01-27T10:30:00"
}
```

---

## 七、任务调度

### 7.1 功能说明

支持定时执行迁移任务，包括：
- Cron 表达式调度
- 延迟任务
- 周期性任务
- 任务队列

### 7.2 使用方式

#### 延迟任务

```java
@Autowired
private MigrationScheduler scheduler;

// 延迟60秒执行
String taskId = scheduler.scheduleTask(config, 60);
```

#### 周期性任务

```java
// 初始延迟10秒，每3600秒（1小时）执行一次
String taskId = scheduler.schedulePeriodicTask(config, 10, 3600);
```

#### Cron 任务

```java
// 每天凌晨2点执行
String taskId = scheduler.scheduleTask(config, "0 0 2 * * ?");
```

#### 任务队列

```java
// 提交到队列，优先级10
String taskId = scheduler.submitToQueue(config, 10);
```

### 7.3 取消任务

```java
// 取消定时任务
scheduler.cancelTask(taskId);
```

---

## 八、完整示例

### 8.1 混合迁移场景

```java
@Service
@RequiredArgsConstructor
public class DatabaseMigrationService {
    
    private final DataMigrationService migrationService;
    private final BinlogListener binlogListener;
    private final MigrationScheduler scheduler;
    
    /**
     * 完整的迁移流程：全量迁移 + 增量同步
     */
    public void fullMigrationWithIncrementalSync() {
        // 1. 执行全量迁移
        MigrationConfig fullConfig = MigrationConfig.builder()
                .source(...)
                .target(...)
                .mode(MigrationConfig.MigrationMode.FULL)
                .enableValidation(true)
                .autoFixInconsistent(true)
                .enableCheckpoint(true)
                .build();
        
        MigrationResult fullResult = migrationService.migrate(fullConfig);
        
        if (fullResult.getStatus() == MigrationResult.MigrationStatus.SUCCESS) {
            // 2. 启动增量同步
            BinlogListener.BinlogListenerConfig binlogConfig = BinlogListener.BinlogListenerConfig.builder()
                    .sourceDataSource(sourceDataSource)
                    .targetDataSource(targetDataSource)
                    .binlogFile(fullResult.getBinlogFile())      // 从全量迁移结束位置开始
                    .binlogPosition(fullResult.getBinlogPosition())
                    .build();
            
            String binlogTaskId = binlogListener.startListening(binlogConfig);
            log.info("增量同步已启动，Task ID: {}", binlogTaskId);
        }
    }
    
    /**
     * 使用双写进行平滑切换
     */
    @DualWrite(
        source = "sourceDataSource",
        target = "targetDataSource",
        tables = {"user", "order"},
        order = DualWrite.WriteOrder.SOURCE_FIRST,
        async = false,
        rollbackOnFailure = true
    )
    public void saveUser(User user) {
        // 业务逻辑：同时写入源库和目标库
    }
}
```

### 8.2 定时迁移任务

```java
@Configuration
@EnableScheduling
public class MigrationScheduleConfig {
    
    @Autowired
    private MigrationScheduler scheduler;
    
    /**
     * 每天凌晨2点执行全量迁移
     */
    @Scheduled(cron = "0 0 2 * * ?")
    public void dailyMigration() {
        MigrationConfig config = MigrationConfig.builder()
                .source(...)
                .target(...)
                .build();
        
        scheduler.scheduleTask(config, 0);  // 立即执行
    }
}
```

---

## 九、最佳实践

### 9.1 迁移流程

1. **准备阶段**
   - 备份源数据库
   - 配置目标数据库
   - 开启 MySQL binlog（ROW 格式）

2. **全量迁移**
   - 执行全量迁移
   - 启用数据校验和自动修复
   - 记录 binlog 位置

3. **增量同步**
   - 启动 Binlog 监听
   - 实时同步增量数据

4. **双写阶段**
   - 启用 `@DualWrite` 注解
   - 同时写入源库和目标库

5. **切换阶段**
   - 逐步切换流量到目标库
   - 监控数据一致性

6. **完成阶段**
   - 停止双写
   - 停止增量同步
   - 下线源库

### 9.2 性能优化

1. **批量大小**：根据表大小调整 `batchSize`
2. **并发数**：根据服务器性能调整 `threadCount`
3. **异步双写**：使用 `async = true` 提高性能
4. **断点间隔**：根据数据量调整 `checkpointInterval`

### 9.3 监控告警

1. **进度监控**：定期查询迁移进度
2. **错误监控**：监控迁移失败和校验不一致
3. **性能监控**：监控迁移速度和资源使用

---

## 十、注意事项

### 10.1 Binlog 监听

- 需要 MySQL 开启 binlog（ROW 格式）
- 需要 REPLICATION SLAVE 权限
- 建议使用独立的 binlog 监听库（如 mysql-binlog-connector-java）

### 10.2 双写功能

- 双写会增加写入延迟
- 建议在迁移期间使用，迁移完成后移除
- 异步双写不保证强一致性

### 10.3 数据校验

- 大数据量校验可能耗时较长
- 自动修复需要主键支持
- 建议在业务低峰期执行

---

## 十一、API 参考

### 11.1 Binlog 监听

- `POST /api/migration/binlog/start` - 启动监听
- `POST /api/migration/binlog/stop/{taskId}` - 停止监听
- `GET /api/migration/binlog/status/{taskId}` - 查询状态

### 11.2 进度查询

- `GET /api/migration/progress/{taskId}` - 查询进度
- `GET /api/migration/progress/task/{taskId}` - 查询任务信息
- `GET /api/migration/progress/checkpoint/{taskId}` - 查询断点

---

## 十二、总结

### 12.1 功能完整性

✅ **Binlog 增量同步**：完整实现  
✅ **双写功能**：注解方式，灵活配置  
✅ **数据校验增强**：自动修复不一致数据  
✅ **断点续传**：支持任务中断后继续  
✅ **进度查询**：实时查询迁移进度  
✅ **任务调度**：支持多种调度方式  

### 12.2 适用场景

- ✅ 数据库迁移（全量+增量）
- ✅ 数据库升级
- ✅ 数据拆分
- ✅ 异地多活
- ✅ 数据备份

### 12.3 技术亮点

1. **热迁移**：业务不停服
2. **实时同步**：基于 binlog 的增量同步
3. **平滑切换**：双写功能保证数据一致性
4. **可靠性**：断点续传和自动修复
5. **易用性**：注解方式，配置简单

