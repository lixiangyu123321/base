# 基于游标的大批量数据更新方案

## 文档信息

- **创建日期**: 2025-12-26
- **问题类型**: 大批量数据更新、内存优化、游标查询
- **参考代码**: `UpdateServiceImpl` 类中的游标更新方法
- **影响范围**: service 模块、dal 模块

---

## 问题概述

在处理大批量数据更新时，如果一次性将所有数据加载到内存中，会导致以下问题：

1. **内存溢出**：数据量过大时可能导致 `OutOfMemoryError`
2. **GC 压力**：大量对象创建和回收会增加 GC 压力
3. **系统响应变慢**：内存占用过高会影响系统整体性能
4. **数据库连接占用时间长**：长时间占用数据库连接，影响并发性能

### 传统方式的问题

```java
// 传统方式：一次性查询所有数据
Example example = new Example(EvaluatingDO.class);
List<EvaluatingDO> evaluatingList = evaluatingMapper.selectByExample(example);
// 问题：如果数据量很大（如 100 万条），会一次性加载到内存
```

---

## 解决方案：基于游标的分批查询和更新

### 核心思想

**游标（Cursor）**：基于有序字段（如主键ID、创建时间）进行分批查询，每次只查询一批数据，处理完后继续查询下一批，直到没有更多数据。

### 优势

1. **内存占用可控**：每次只加载一批数据到内存
2. **支持无限数据量**：理论上可以处理任意大小的数据量
3. **数据库连接占用时间短**：每批查询完成后可以释放连接
4. **可以中断和恢复**：基于游标位置，可以记录进度并支持中断后恢复

---

## 实现方案

### 方案一：基于主键ID的游标更新

#### 1.1 实现原理

使用主键ID作为游标，每次查询 `id > lastId` 的记录，按ID升序排列，限制查询数量。

**SQL 示例**：
```sql
SELECT * FROM t_aigc_evaluating 
WHERE id > #{lastId} 
ORDER BY id ASC 
LIMIT #{batchSize}
```

#### 1.2 代码实现

**Mapper 接口**：
```java
/**
 * 基于主键ID的游标查询
 *
 * @param lastId 上一批查询的最后一个ID，首次查询传null或0
 * @param batchSize 每批查询的数量
 * @return 返回查询到的记录列表
 */
List<EvaluatingDO> selectByCursorId(Long lastId, Integer batchSize);
```

**Mapper XML**：
```xml
<select id="selectByCursorId" resultMap="BaseResultMap">
    SELECT
    <include refid="Base_Column_List"/>
    FROM `t_aigc_evaluating`
    <where>
        <if test="lastId != null and lastId > 0">
            AND id > #{lastId}
        </if>
    </where>
    ORDER BY id ASC
    LIMIT #{batchSize}
</select>
```

**Service 实现**：
```java
@Override
@Transactional(rollbackFor = Exception.class)
public UpdateResult batchUpdateByCursorId(Integer batchSize, Integer maxCount) {
    if (batchSize == null || batchSize <= 0) {
        batchSize = 1000; // 默认批次大小
    }
    
    long startTime = System.currentTimeMillis();
    int totalUpdated = 0;
    Long lastId = 0L; // 游标起始位置
    
    // 循环查询和更新，直到没有更多数据
    while (true) {
        // 1. 基于游标查询一批数据
        List<EvaluatingDO> batchList = evaluatingMapper.selectByCursorId(lastId, batchSize);
        
        if (batchList == null || batchList.isEmpty()) {
            break; // 没有更多数据
        }
        
        // 2. 准备更新数据
        Date updateTime = new Date();
        for (EvaluatingDO evaluating : batchList) {
            evaluating.setUpdateTime(updateTime);
            evaluating.setModifier("cursor_id_update");
            evaluating.setRemark("游标ID更新_" + System.currentTimeMillis());
        }
        
        // 3. 批量更新当前批次
        int updated = evaluatingMapper.batchUpdate(batchList);
        totalUpdated += updated;
        
        // 4. 更新游标位置
        lastId = batchList.get(batchList.size() - 1).getId();
        
        // 5. 如果查询到的数据少于批次大小，说明已经是最后一批
        if (batchList.size() < batchSize) {
            break;
        }
        
        // 6. 检查是否达到最大更新数量
        if (maxCount != null && totalUpdated >= maxCount) {
            break;
        }
    }
    
    return new UpdateResult(totalUpdated, executionTime, executionTime / 1000.0, "游标ID批量更新");
}
```

#### 1.3 适用场景

- **主键ID连续或基本连续**：ID 是自增的，或者分布相对均匀
- **需要按ID顺序处理**：业务要求按ID顺序更新
- **数据量非常大**：百万级、千万级数据

#### 1.4 注意事项

- **ID 不连续的影响**：如果ID有大量跳跃，可能查询到空结果，但不会影响正确性
- **ID 重复问题**：如果ID可能重复，需要额外处理
- **并发更新问题**：如果有其他进程在插入数据，可能导致游标位置偏移

---

### 方案二：基于创建时间的游标更新

#### 2.1 实现原理

使用创建时间作为游标，每次查询 `create_time > lastTime` 的记录，按时间升序排列，限制查询数量。

**SQL 示例**：
```sql
SELECT * FROM t_aigc_evaluating 
WHERE create_time > #{lastTime} 
ORDER BY create_time ASC, id ASC 
LIMIT #{batchSize}
```

#### 2.2 代码实现

**Mapper 接口**：
```java
/**
 * 基于创建时间的游标查询
 *
 * @param lastTime 上一批查询的最后一个时间，首次查询传null
 * @param batchSize 每批查询的数量
 * @return 返回查询到的记录列表
 */
List<EvaluatingDO> selectByCursorTime(Date lastTime, Integer batchSize);
```

**Mapper XML**：
```xml
<select id="selectByCursorTime" resultMap="BaseResultMap">
    SELECT
    <include refid="Base_Column_List"/>
    FROM `t_aigc_evaluating`
    <where>
        <if test="lastTime != null">
            AND create_time > #{lastTime}
        </if>
    </where>
    ORDER BY create_time ASC, id ASC
    LIMIT #{batchSize}
</select>
```

**Service 实现**：
```java
@Override
@Transactional(rollbackFor = Exception.class)
public UpdateResult batchUpdateByCursorTime(Integer batchSize, Integer maxCount) {
    // 实现逻辑与基于ID的游标更新类似
    // 区别：使用 createTime 作为游标，而不是 id
}
```

#### 2.3 适用场景

- **按时间范围处理**：需要按创建时间顺序处理数据
- **时间字段有索引**：`create_time` 字段有索引，查询性能好
- **时间分布相对均匀**：数据按时间分布相对均匀

#### 2.4 注意事项

- **时间精度问题**：如果同一时间有多条记录，需要配合ID排序
- **时区问题**：确保时间比较的时区一致
- **时间字段为空**：需要处理 `create_time` 为 null 的情况

---

### 方案三：基于游标的线程池批量更新（推荐）

#### 3.1 实现原理

结合游标查询和线程池并发处理的优势：
1. 使用游标分批查询数据（避免内存溢出）
2. 将每批数据分成多个任务提交到线程池（充分利用并发）
3. 每个任务使用批量更新（减少网络往返）

**流程**：
```
游标查询批次（5000条）
    ↓
分成多个线程池任务批次（每批1000条）
    ↓
线程池并发执行批量更新
    ↓
等待所有任务完成
    ↓
继续下一个游标查询批次
```

#### 3.2 代码实现

```java
@Override
@Transactional(rollbackFor = Exception.class)
public UpdateResult batchUpdateByCursorIdWithThreadPool(
        Integer batchSize,      // 游标查询批次大小（如 5000）
        Integer threadBatchSize, // 线程池任务批次大小（如 1000）
        Integer maxCount) {      // 最大更新数量
    AtomicInteger totalUpdated = new AtomicInteger(0);
    Long lastId = 0L;
    
    while (true) {
        // 1. 游标查询一批数据
        List<EvaluatingDO> cursorBatch = evaluatingMapper.selectByCursorId(lastId, batchSize);
        if (cursorBatch.isEmpty()) {
            break;
        }
        
        // 2. 将游标批次分成多个线程池任务批次
        int threadBatchCount = (cursorBatch.size() + threadBatchSize - 1) / threadBatchSize;
        CountDownLatch latch = new CountDownLatch(threadBatchCount);
        AtomicInteger batchUpdated = new AtomicInteger(0);
        
        // 3. 提交任务到线程池
        for (int i = 0; i < threadBatchCount; i++) {
            final int start = i * threadBatchSize;
            final int end = Math.min((i + 1) * threadBatchSize, cursorBatch.size());
            
            batchUpdateExecutor.execute(() -> {
                try {
                    // 获取当前任务批次的数据
                    List<EvaluatingDO> threadBatch = cursorBatch.subList(start, end);
                    
                    // 准备更新数据
                    for (EvaluatingDO evaluating : threadBatch) {
                        evaluating.setUpdateTime(new Date());
                        evaluating.setModifier("cursor_thread_pool_update");
                    }
                    
                    // 批量更新
                    int updated = evaluatingMapper.batchUpdate(threadBatch);
                    batchUpdated.addAndGet(updated);
                } finally {
                    latch.countDown();
                }
            });
        }
        
        // 4. 等待所有任务完成
        latch.await();
        
        // 5. 更新总计数和游标位置
        totalUpdated.addAndGet(batchUpdated.get());
        lastId = cursorBatch.get(cursorBatch.size() - 1).getId();
    }
    
    return new UpdateResult(totalUpdated.get(), executionTime, executionTime / 1000.0, "游标ID线程池批量更新");
}
```

#### 3.3 适用场景

- **数据量非常大**：百万级、千万级数据
- **需要高性能**：需要充分利用多核CPU和并发处理
- **内存有限**：不能一次性加载所有数据到内存

#### 3.4 性能优势

- **内存占用可控**：每次只加载游标批次大小的数据
- **并发处理**：充分利用多核CPU
- **批量更新**：减少网络往返次数
- **性能最优**：结合了游标和线程池的优势

---

## 性能对比

| 更新方式 | 内存占用 | 支持数据量 | 性能 | 适用场景 |
|---------|---------|-----------|------|---------|
| **传统方式** | O(n) | < 10万 | 中等 | 小批量数据 |
| **游标ID更新** | O(batchSize) | 无限 | 良好 | 大批量数据，ID连续 |
| **游标时间更新** | O(batchSize) | 无限 | 良好 | 大批量数据，按时间处理 |
| **游标+线程池** | O(batchSize) | 无限 | **最优** | **超大批量数据，需要高性能** |

---

## 最佳实践

### 1. 批次大小选择

#### 游标查询批次大小（batchSize）

| 数据总量 | 推荐批次大小 | 说明 |
|---------|------------|------|
| < 10万 | 1000 | 小批量，批次可以小一些 |
| 10万 - 100万 | 5000 | 中等批量，平衡内存和查询次数 |
| > 100万 | 5000-10000 | 大批量，批次可以大一些 |

#### 线程池任务批次大小（threadBatchSize）

| 场景 | 推荐批次大小 | 说明 |
|-----|------------|------|
| 网络延迟高 | 1000-1500 | 减少网络往返 |
| 网络延迟低 | 500-1000 | 平衡并发和开销 |
| CPU核心数多 | 1000-1500 | 充分利用并发 |
| CPU核心数少 | 500-800 | 避免过度并发 |

### 2. 游标字段选择

#### 选择主键ID的场景

- ✅ ID 是自增的，分布连续
- ✅ 需要按ID顺序处理
- ✅ ID 字段有索引，查询性能好

#### 选择创建时间的场景

- ✅ 需要按时间顺序处理
- ✅ 时间字段有索引
- ✅ 时间分布相对均匀

### 3. 并发控制

#### 单线程游标更新

```java
// 适合：数据量中等，不需要高并发
batchUpdateByCursorId(1000, null);
```

#### 线程池游标更新

```java
// 适合：数据量很大，需要高并发
batchUpdateByCursorIdWithThreadPool(5000, 1000, null);
```

### 4. 中断和恢复

如果需要支持中断和恢复，可以记录游标位置：

```java
// 记录游标位置
Long lastProcessedId = getLastProcessedId();

// 从上次位置继续
UpdateResult result = batchUpdateByCursorId(1000, null);
// 从 lastId = 0 改为 lastId = lastProcessedId
```

---

## API 使用示例

### 1. 基于游标ID的批量更新

```bash
POST /api/update/batchUpdateByCursorId
{
    "batchSize": 1000,      # 每批查询数量
    "maxCount": 100000      # 最大更新数量（可选，null表示不限制）
}
```

### 2. 基于游标时间的批量更新

```bash
POST /api/update/batchUpdateByCursorTime
{
    "batchSize": 1000,
    "maxCount": null        # 不限制，处理所有数据
}
```

### 3. 基于游标的线程池批量更新（推荐）

```bash
POST /api/update/batchUpdateByCursorIdWithThreadPool
{
    "batchSize": 5000,          # 游标查询批次大小
    "threadBatchSize": 1000,    # 线程池任务批次大小
    "maxCount": null            # 不限制
}
```

---

## 注意事项

### 1. 事务管理

- **大事务问题**：如果数据量非常大，整个更新过程在一个事务中，可能导致事务日志过大
- **建议**：考虑将每个游标批次作为独立事务，或者使用分布式事务

### 2. 并发更新冲突

- **问题**：如果有其他进程在更新数据，可能导致游标位置偏移
- **解决**：使用乐观锁或悲观锁，或者选择业务低峰期执行

### 3. 数据一致性

- **问题**：在更新过程中，如果有新数据插入，可能被遗漏
- **解决**：使用时间范围查询，或者记录最后处理的时间点

### 4. 性能监控

- **监控指标**：
  - 每批处理时间
  - 内存占用
  - 数据库连接数
  - 线程池使用情况

### 5. 错误处理

- **部分失败**：如果某批更新失败，需要记录失败位置，支持重试
- **全部回滚**：如果使用大事务，失败会导致全部回滚，需要权衡

---

## 总结

### 核心优势

1. **内存占用可控**：每次只加载一批数据，支持处理任意大小的数据量
2. **性能优秀**：结合游标和线程池，性能最优
3. **灵活可控**：支持限制更新数量，支持中断和恢复

### 推荐方案

**对于超大批量数据更新，强烈推荐使用：基于游标的线程池批量更新**

```java
// 推荐配置
batchUpdateByCursorIdWithThreadPool(
    5000,    // 游标查询批次：5000条
    1000,    // 线程池任务批次：1000条
    null     // 不限制总数
);
```

### 适用场景总结

| 数据量 | 推荐方案 | 批次大小配置 |
|--------|---------|------------|
| < 1万 | 传统批量更新 | - |
| 1万 - 10万 | 线程池批量更新 | batchSize: 1000 |
| 10万 - 100万 | 游标ID更新 | batchSize: 5000 |
| > 100万 | **游标+线程池更新** | **batchSize: 5000, threadBatchSize: 1000** |

---

## 更新记录

| 日期 | 版本 | 更新内容 | 作者 |
|------|------|---------|------|
| 2025-12-26 | 1.0 | 初始版本，实现基于游标的大批量数据更新方案 | lixiangyu |

---

**文档版本**: 1.0  
**最后更新**: 2025-12-26  
**适用项目**: com.lixiangyu.demo

